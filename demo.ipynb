{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 电池数据异常检测\n",
    "### 此notebook为异常检测比赛的参考DEMO，包括数据划分、模型训练和结果检测等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "from os.path import join, split\n",
    "from os import getcwd\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc\n",
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "from pyod.models.auto_encoder_torch import AutoEncoder, check_array, inner_autoencoder, check_is_fitted, \\\n",
    "    pairwise_distances_no_broadcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载训练集的pkl文件\n",
    "\n",
    "训练集的label存放在pkl里面，可以通过它并区分正常片段和异常片段  \n",
    "注意需要输入训练集对应的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=join(split(getcwd())[0], 'static', 'train')#存放数据的路径\n",
    "pkl_files = glob(data_path+'/*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28389/28389 [00:02<00:00, 13398.29it/s]\n"
     ]
    }
   ],
   "source": [
    "ind_pkl_files = []#存放标签为0的文件\n",
    "ood_pkl_files = []#存放标签为1的文件\n",
    "for each_path in tqdm(pkl_files):\n",
    "    this_pkl_file = torch.load(each_path)#下载pkl文件\n",
    "    if this_pkl_file[1]['label'] == '00':\n",
    "        ind_pkl_files.append(each_path)\n",
    "    else:\n",
    "        ood_pkl_files.append(each_path)\n",
    "\n",
    "random.seed(0)\n",
    "#排序并打乱存放车辆序号的集合\n",
    "random.shuffle(ind_pkl_files)\n",
    "random.shuffle(ood_pkl_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分训练集和测试集  \n",
    "\n",
    "参赛选手可以根据需求自由化分数据集\n",
    "\n",
    "这里选取训练集中正常片段的1/4作为训练集，正常片段的剩余3/4和异常片段作为测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pkl_files=[]\n",
    "for i in range(len(ind_pkl_files)//4):\n",
    "    train_pkl_files.append(ind_pkl_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pkl_files=[]\n",
    "for j in range(len(ind_pkl_files)//4,len(ind_pkl_files)):\n",
    "    test_pkl_files.append(ind_pkl_files[j])\n",
    "for item in ood_pkl_files:\n",
    "    test_pkl_files.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义加载函数，并对数据进行正则化  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  load_data(pkl_list,label=True):\n",
    "    '''\n",
    "    输入pkl的列表，进行文件加载\n",
    "    label=True用来加载训练集\n",
    "    label=False用来加载真正的测试集，真正的测试集无标签\n",
    "    '''\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "\n",
    "    for  each_pkl in pkl_list:\n",
    "        item = torch.load(each_pkl)\n",
    "        # 此处选取的是每个滑窗的最后一条数据，仅供参考，可以选择其他的方法，比如均值或者其他处理时序数据的网络\n",
    "        # 此处选取了前7个特征，可以需求选取特征数量\n",
    "        X.append(item[0][:,0:7][-1])\n",
    "        if label:\n",
    "            y.append(int(item[1]['label'][0]))\n",
    "    X = np.vstack(X)\n",
    "    if label:\n",
    "        y = np.vstack(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=load_data(train_pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test=load_data(test_pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mean = np.mean(X_train, axis=0)\n",
    "_std = np.std(X_train, axis=0)\n",
    "X_train = (X_train - _mean) / (_std + 1e-4)\n",
    "X_test = (X_test - _mean) / (_std + 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义DataLoader数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyODDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"PyOD Dataset class for PyTorch Dataloader\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y=None, mean=None, std=None):\n",
    "        super(PyODDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()#将tensor类型转换列表格式\n",
    "        sample = self.X[idx, :]\n",
    "\n",
    "        # if self.mean.any():\n",
    "        #     sample = (sample - self.mean) / (self.std + 1e-5)\n",
    "        #torch.from_numpy()将numpy类型转换为tensor类型\n",
    "        return torch.from_numpy(sample), idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义AutoEncoder类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car_AutoEncoder(AutoEncoder):\n",
    "    \n",
    "    '''\n",
    "    使用autoencoder 来进行模型的训练，默认采用无监督的训练方式\n",
    "    '''\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # validate inputs X and y (optional)\n",
    "        X = check_array(X)\n",
    "        self._set_n_classes(y)\n",
    "\n",
    "        n_samples, n_features = X.shape[0], X.shape[1] #获取样本个数和特征个数\n",
    "\n",
    "        # 是否进行预处理操作\n",
    "        if self.preprocessing:\n",
    "            self.mean, self.std = np.mean(X, axis=0), np.std(X, axis=0)\n",
    "            train_set = PyODDataset(X=X, mean=self.mean, std=self.std)\n",
    "\n",
    "        else:\n",
    "            train_set = PyODDataset(X=X)\n",
    "        #构建数据生成器\n",
    "        train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                                   batch_size=self.batch_size,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "        # initialize the model ,初始化模型\n",
    "        #hidden_neurons列表，可选（默认值为[64， 32]）每个隐藏层的神经元数。因此，该网络的结构为[n_features，64，32，32，64，n_features]\n",
    "        #hidden_activationstr，可选（默认值='relu'）用于隐藏层的激活函数。所有隐藏层都强制使用相同类型的激活\n",
    "        #batch_norm布尔值，可选（默认值为 True）是否应用批量规范化。\n",
    "        #dropout_rate浮点数 （0.， 1），可选（默认值 = 0.2）要跨所有层使用的分级。\n",
    "        \n",
    "        self.model = inner_autoencoder(\n",
    "            n_features=n_features,\n",
    "            hidden_neurons=self.hidden_neurons,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            batch_norm=self.batch_norm,\n",
    "            hidden_activation=self.hidden_activation)\n",
    "\n",
    "        #将model放入device中\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        # 训练自动编码器以找到最佳编码器\n",
    "        self._train_autoencoder(train_loader)\n",
    "\n",
    "        self.model.load_state_dict(self.best_model_dict)\n",
    "        self.decision_scores_ = self.decision_function(X)#获得输入样本的异常得分\n",
    "        \n",
    "        self._process_decision_scores()  \n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X): \n",
    "        \"\"\"使用拟合的检测器预测X的原始异常分数。\n",
    "\n",
    "            输入样本的异常分数是基于不同的检测器算法。为保持一致性，离群值分配为异常分数越大的。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array of shape (n_samples, n_features)\n",
    "            形状的numpy数组（n_samples，n_features）训练输入样本。仅接受稀疏矩阵，如果它们由基础估计器支持。\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        anomaly_scores : numpy array of shape (n_samples,)\n",
    "            形状的numpy数组（n_samples，）输入样本的异常得分。\n",
    "        \"\"\"\n",
    "        #对估算器执行is_fitted验证。通过验证是否存在拟合属性（以下划线结尾）来检查估计量是否拟合，否则通过给定消息引发NotFittedError。此实用程序旨在由估计器本身在内部使用，通常在其自己的预测/变换方法中使用。\n",
    "        check_is_fitted(self, ['model', 'best_model_dict'])\n",
    "        # X = check_array(X)\n",
    "\n",
    "        # note the shuffle may be true but should be False\n",
    "        if self.preprocessing:\n",
    "            dataset = PyODDataset(X=X, mean=self.mean, std=self.std)\n",
    "        else:\n",
    "            dataset = PyODDataset(X=X)\n",
    "\n",
    "        dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                                 batch_size=self.batch_size,\n",
    "                                                 shuffle=False) #要设置为False\n",
    "        # enable the evaluation mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # construct the vector for holding the reconstruction error\n",
    "        outlier_scores = np.zeros([X.shape[0], ])#形状为（X.shape[0],)\n",
    "        with torch.no_grad():\n",
    "            for data, data_idx in dataloader:\n",
    "                data_cuda = data.to(self.device).float()\n",
    "                # this is the outlier score\n",
    "                outlier_scores[data_idx] = pairwise_distances_no_broadcast(\n",
    "                    data, self.model(data_cuda).cpu().numpy())\n",
    "\n",
    "        return outlier_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义训练和评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了便于复现这里固定了随机种子\n",
    "def same_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "def train(X_train,X_test,hidden_neurons,learning_rate,epochs,batch_size,contamination,drop_out,hidden_activation):\n",
    "    same_seeds(42)\n",
    "    clf_name = 'auto_encoder'\n",
    "    clf = Car_AutoEncoder(hidden_neurons=hidden_neurons,  batch_size=batch_size, epochs=epochs,learning_rate=learning_rate,\n",
    "                                    dropout_rate=drop_out,contamination=contamination,hidden_activation=hidden_activation)\n",
    "    clf.fit(X_train)\n",
    "\n",
    "    y_train_pred = clf.labels_ # 返回训练数据上的分类标签 (0: 正常值, 1: 异常值) # binary labels (0: inliers, 1: outliers)\n",
    "    y_train_scores = clf.decision_scores_  # 返回训练数据上的异常值 (分值越大越异常)# raw outlier scores\n",
    "    y_test_pred = clf.predict(X_test) # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值) # outlier labels (0 or 1)\n",
    "    y_test_scores = clf.decision_function(X_test)   #返回未知数据上的异常值 (分值越大越异常) # outlier scores\n",
    "    return clf, y_test_scores\n",
    "\n",
    "def evaluate(label,score):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(label, score, pos_label=1)\n",
    "    AUC = auc(fpr, tpr)\n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的训练和AUC计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义合适的参数\n",
    "hidden_neurons=[ 32,64,64, 32]\n",
    "learning_rate=0.03\n",
    "epochs=15\n",
    "batch_size=640\n",
    "contamination=0.005\n",
    "drop_out=0.2\n",
    "hidden_activation='sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: training loss 0.8547998607158661 \n",
      "epoch 1: training loss 0.5165457308292389 \n",
      "epoch 2: training loss 0.4897191345691681 \n",
      "epoch 3: training loss 0.45958670079708097 \n",
      "epoch 4: training loss 0.42661191523075104 \n",
      "epoch 5: training loss 0.405013445019722 \n",
      "epoch 6: training loss 0.3793113887310028 \n",
      "epoch 7: training loss 0.35370959639549254 \n",
      "epoch 8: training loss 0.3494845539331436 \n",
      "epoch 9: training loss 0.34357334673404694 \n",
      "epoch 10: training loss 0.33573390245437623 \n",
      "epoch 11: training loss 0.3373540133237839 \n",
      "epoch 12: training loss 0.3275435507297516 \n",
      "epoch 13: training loss 0.3290592908859253 \n",
      "epoch 14: training loss 0.3318335235118866 \n"
     ]
    }
   ],
   "source": [
    "same_seeds(42)\n",
    "clf = Car_AutoEncoder(hidden_neurons=hidden_neurons,  batch_size=batch_size, epochs=epochs,learning_rate=learning_rate,\n",
    "                                     dropout_rate=drop_out,contamination=contamination,hidden_activation=hidden_activation)\n",
    "clf.fit(X_train)\n",
    "y_test_pred = clf.predict(X_test) # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值) # outlier labels (0 or 1)\n",
    "y_test_scores = clf.decision_function(X_test)   #返回未知数据上的异常值 (分值越大越异常) # outlier scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770866389859673"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC1=evaluate(y_test,y_test_scores)\n",
    "AUC1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的保存、加载和提交文件生成  \n",
    "\n",
    "需要输入测试数据的路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存和加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(clf,\"clf1.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Car_AutoEncoder(batch_norm=True, batch_size=640, contamination=0.005,\n",
       "        device=device(type='cpu'), dropout_rate=0.2, epochs=15,\n",
       "        hidden_activation='sigmoid', hidden_neurons=[32, 64, 64, 32],\n",
       "        learning_rate=0.03, loss_fn=MSELoss(), preprocessing=True,\n",
       "        weight_decay=1e-05)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=torch.load(\"clf1.torch\")\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path3=join(split(getcwd())[0], 'static', 'test_A')\n",
    "test1_files = glob(data_path3+'/*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val,_=load_data(test1_files,label=False)\n",
    "_mean = np.mean(X_val, axis=0)\n",
    "_std = np.std(X_val, axis=0)\n",
    "X_val = (X_val - _mean) / (_std + 1e-4)\n",
    "y_val_pred = clf.predict(X_val) # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值) # outlier labels (0 or 1)\n",
    "y_val_scores = clf.decision_function(X_val)   #返回未知数据上的异常值 (分值越大越异常) # outlier scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6234/6234 [00:00<00:00, 966056.72it/s]\n"
     ]
    }
   ],
   "source": [
    "#记录文件名和对应的异常得分\n",
    "predict_result={}\n",
    "file_ids = [int(split(test1_file)[1].split('.')[0]) for test1_file in test1_files]\n",
    "file_ids_argsorted = np.argsort(file_ids)\n",
    "for i in tqdm(range(len(test1_files))):\n",
    "    file_id = file_ids_argsorted[i]\n",
    "    file = test1_files[file_id]\n",
    "    name = split(file)[1]\n",
    "    predict_result[name]=y_val_scores[file_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_score=pd.DataFrame(list(predict_result.items()),columns=['file_name','score'])#列名必须为这俩个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_score.to_csv('submision.csv',index = False) #保存为比赛要求的csv文件\n",
    "predict_score[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
